import asyncio
import json
import base64
import time
import os
import sys
import numpy as np
import cv2
import websockets
import threading
import logging  # ä¸´æ—¶å¤‡ç”¨

os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(current_dir, 'galbot'))

from galbot.core_proto import time_pb2, header_pb2
from galbot.spatial_proto import twist_pb2, pose_pb2
from galbot.singorix_proto import singorix_command_pb2, singorix_sensor_pb2, singorix_error_pb2, singorix_target_pb2
from galbot.sensor_proto import imu_pb2, image_pb2, camera_pb2, joy_pb2
from galbot.tf2_proto import tf2_message_pb2


from operating_platform.robot.robots.utils import RobotDeviceNotConnectedError
from operating_platform.robot.robots.configs import GalbotG1RobotConfig
from operating_platform.robot.robots.com_configs.cameras import CameraConfig, OpenCVCameraConfig
from operating_platform.robot.robots.camera import Camera
# å¦‚æœ colored_logging æœ‰é—®é¢˜ï¼Œä¸´æ—¶ç”¨æ ‡å‡† logger
try:
    from operating_platform.utils.colored_logging import setup_colored_logger
    logger = setup_colored_logger(__name__)
except Exception:
    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class RobotSocket:
    def __init__(self, robot_ip, bridge_port=10800):
        self.robot_ip = robot_ip
        self.bridge_port = bridge_port
        self.ws = None
        self.uri = f"ws://{self.robot_ip}:{self.bridge_port}"
        self.task = None  # listen ä»»åŠ¡

        # çŠ¶æ€å­˜å‚¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.latest_states = {}
        self.state_lock = threading.Lock()

        # å›¾åƒç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.latest_images = {}  # topic -> numpy array
        self.image_lock = threading.Lock()

        # æ–°å¢ï¼šç»“æ„åŒ–å­˜å‚¨ç‰¹å®šå…³èŠ‚ç»„æ•°æ®
        self.arm_joint_data = {
            "right_arm": {},
            "left_arm": {}
        }
        self.gripper_data = {
            "right_gripper": {},
            "left_gripper": {}
        }

        # Protobuf ç±»å‹æ˜ å°„
        self.protobuf_type_map = {
            "galbot.sensor_proto.CompressedImage": image_pb2.CompressedImage,
            "galbot.sensor_proto.CameraInfo": camera_pb2.CameraInfo,
            "galbot.singorix_proto.SingoriXSensor": singorix_sensor_pb2.SingoriXSensor,
            "galbot.singorix_proto.SingoriXError": singorix_error_pb2.SingoriXError,
            "galbot.singorix_proto.SingoriXTarget": singorix_target_pb2.SingoriXTarget,
            "galbot.tf2_proto.TF2Message": tf2_message_pb2.TF2Message,
            "galbot.sensor_proto.Joy": joy_pb2.Joy
        }

        # å¼‚æ­¥ä»»åŠ¡æ§åˆ¶
        self.running = False

    async def connect(self):
        """å»ºç«‹ WebSocket è¿æ¥"""
        try:
            self.ws = await websockets.connect(self.uri)
            logger.info(f"âœ… WebSocket å·²è¿æ¥: {self.uri}")
            self.running = True
            self.task = asyncio.create_task(self.listen())
        except Exception as e:
            logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")

    async def listen(self):
        """ç›‘å¬ WebSocket æ¶ˆæ¯"""
        try:
            async for message in self.ws:
                try:
                    msg_json = json.loads(message)
                    op = msg_json.get("op")

                    if op == "message":
                        await self._process_protobuf_message(msg_json)
                    elif op == "heartbeat":
                        await self._process_heartbeat(msg_json)
                    elif op == "error":
                        await self._process_error(msg_json)
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥æ“ä½œç±»å‹: {op}")

                except json.JSONDecodeError:
                    logger.error(f"âŒ JSON è§£æå¤±è´¥: {message[:100]}...")
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

        except websockets.exceptions.ConnectionClosed as e:
            logger.info(f"ğŸ”Œ è¿æ¥å…³é—­: {e}")
        finally:
            self.running = False

    async def _process_protobuf_message(self, message):
        """å¤„ç† protobuf æ¶ˆæ¯"""
        topic = message.get("topic")
        type_str = message.get("type")
        data_b64 = message.get("data")

        if not all([topic, type_str, data_b64]):
            logger.error("âŒ ç¼ºå°‘å¿…è¦å­—æ®µ")
            return

        pb_class = self.protobuf_type_map.get(type_str)
        if not pb_class:
            logger.error(f"âŒ æœªçŸ¥ protobuf ç±»å‹: {type_str}")
            return

        try:
            data_bytes = base64.b64decode(data_b64)
            if not data_bytes:
                raise ValueError(f"è§£ç åå¾—åˆ°ç©ºå­—èŠ‚æ•°æ® (topic: {topic})")

            pb_message = pb_class()
            pb_message.ParseFromString(data_bytes)
            if pb_message is None:
                raise ValueError(f"åˆ›å»ºprotobufæ¶ˆæ¯å¯¹è±¡å¤±è´¥ (topic: {topic})")

            # ï¿½ï¿½ï¸ å¤„ç†å›¾åƒï¼šç¼“å­˜åˆ° latest_imagesï¼Œä¸åœ¨è¿™é‡Œæ˜¾ç¤º
            if any(cam in topic for cam in [
                "/right_arm_camera/color/image_raw",
                "/left_arm_camera/color/image_raw",
                "/front_head_camera/right_color/image_raw",
                "/front_head_camera/left_color/image_raw"
            ]) and isinstance(pb_message, image_pb2.CompressedImage):
                np_arr = np.frombuffer(pb_message.data, np.uint8)
                image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
                if image is not None:
                    with self.image_lock:
                        self.latest_images[topic] = image

            # ï¿½ï¿½ å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®
            elif "singorix/wbcs/sensor" in topic:
                self._parse_and_store_joint_data(pb_message)

            # é€šç”¨çŠ¶æ€å­˜å‚¨
            with self.state_lock:
                self.latest_states[topic] = {
                    "message": pb_message,
                    "timestamp": message.get("pub_ts", 0),
                    "received": time.time_ns()
                }

            # logger.info(f"ğŸ“¥ æ¥æ”¶åˆ° {topic} æ¶ˆæ¯: {type_str}")

        except Exception as e:
            logger.error(f"âŒ è§£æ protobuf å¤±è´¥: {e}")

    async def _process_heartbeat(self, message):
        ts = message.get("ts", 0)
        logger.info(f"ğŸ’“ å¿ƒè·³æ—¶é—´æˆ³: {ts}")

    async def _process_error(self, message):
        error_msg = message.get("msg", "æœªçŸ¥é”™è¯¯")
        logger.error(f"â— é”™è¯¯æ¶ˆæ¯: {error_msg}")

    def _parse_and_store_joint_data(self, sensor_msg):
        """è§£æ SingoriXSensor æ¶ˆæ¯ï¼Œæå–å¹¶å­˜å‚¨ arm å’Œ gripper æ•°æ®"""
        if not sensor_msg.joint_sensor_map:
            return

        with self.state_lock:
            for group_name, joint_sensor in sensor_msg.joint_sensor_map.items():
                n = len(joint_sensor.name)
                if n == 0:
                    continue

                joint_data = {}
                for i in range(n):
                    name = joint_sensor.name[i] if i < len(joint_sensor.name) else f"joint{i}"
                    joint_data[name] = {
                        "position": joint_sensor.position[i] if i < len(joint_sensor.position) else 0.0,
                        "velocity": joint_sensor.velocity[i] if i < len(joint_sensor.velocity) else 0.0,
                        "effort": joint_sensor.effort[i] if i < len(joint_sensor.effort) else 0.0,
                        "current": joint_sensor.current[i] if i < len(joint_sensor.current) else 0.0,
                    }

                if group_name == "right_arm":
                    self.arm_joint_data["right_arm"] = joint_data
                elif group_name == "left_arm":
                    self.arm_joint_data["left_arm"] = joint_data
                elif group_name == "right_gripper":
                    self.gripper_data["right_gripper"] = joint_data
                elif group_name == "left_gripper":
                    self.gripper_data["left_gripper"] = joint_data

    def get_arm_state(self, side):
        key = f"{side}_arm"
        with self.state_lock:
            return self.arm_joint_data.get(key, {}).copy()

    def get_gripper_state(self, side):
        key = f"{side}_gripper"
        with self.state_lock:
            return self.gripper_data.get(key, {}).copy()

    def get_all_arm_states(self):
        with self.state_lock:
            return {k: v.copy() for k, v in self.arm_joint_data.items()}

    def get_all_gripper_states(self):
        with self.state_lock:
            return {k: v.copy() for k, v in self.gripper_data.items()}

    def get_latest_state(self, topic):
        with self.state_lock:
            return self.latest_states.get(topic)

    def get_all_topics(self):
        with self.state_lock:
            return list(self.latest_states.keys())

    def get_latest_image(self, topic):
        with self.image_lock:
            return self.latest_images.get(topic)

    def get_all_image_topics(self):
        with self.image_lock:
            return list(self.latest_images.keys())

    async def shutdown(self):
        """å…³é—­è¿æ¥"""
        self.running = False
        if self.ws:
            await self.ws.close()
        if self.task and not self.task.done():
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass
        logger.info("ğŸ”Œ WebSocket å·²å…³é—­")


async def Robot_main(robot_socket: RobotSocket):

    await robot_socket.connect()

    # ç­‰å¾…è¿æ¥å»ºç«‹
    try:
        await asyncio.wait_for(asyncio.sleep(0.1), timeout=10.0)
        if not robot_socket.running:
            raise Exception("WebSocket æœªæˆåŠŸè¿æ¥")
        logger.info("ğŸ”Œ æœºå™¨äººè¿æ¥å·²å»ºç«‹")
    except (asyncio.TimeoutError, Exception) as e:
        logger.error(f"â³ è¿æ¥å¤±è´¥: {e}")
        await robot_socket.shutdown()
        return

    # å›¾åƒçª—å£æ˜ å°„
    topic_to_window = {
        "/right_arm_camera/color/image_raw": "Right Arm Camera",
        "/left_arm_camera/color/image_raw": "Left Arm Camera",
        "/front_head_camera/right_color/image_raw": "Front Head Right Camera",
        "/front_head_camera/left_color/image_raw": "Front Head Left Camera",
    }

    try:
        while robot_socket.running:


            # æ‰“å°çŠ¶æ€
            topics = robot_socket.get_all_topics()
            logger.info(f"ğŸ“Š å½“å‰æ´»è·ƒä¸»é¢˜: {topics}")

            # æ‰“å°å…³èŠ‚æ•°æ®
            right_arm = robot_socket.get_arm_state("right")
            left_arm = robot_socket.get_arm_state("left")
            right_gripper = robot_socket.get_gripper_state("right")
            left_gripper = robot_socket.get_gripper_state("left")

            print("\n=== ğŸ¤– å®æ—¶å…³èŠ‚çŠ¶æ€ ===")
            if right_arm:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in right_arm.items()])
                print(f"ğŸ‘‰ å³è‡‚: {pos_str}")
            if left_arm:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in left_arm.items()])
                print(f"ğŸ‘ˆ å·¦è‡‚: {pos_str}")
            if right_gripper:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in right_gripper.items()])
                print(f"âœ‹ å³å¤¹çˆª: {pos_str}")
            if left_gripper:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in left_gripper.items()])
                print(f"âœ‹ å·¦å¤¹çˆª: {pos_str}")

            await asyncio.sleep(1.0)

    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸»å¾ªç¯å¼‚å¸¸: {e}")
    finally:
        logger.info("ğŸ›‘ æ­£åœ¨å…³é—­æœºå™¨äººè¿æ¥...")

        cv2.destroyAllWindows()
        logger.info("âœ… ä¸»ç¨‹åºå·²å®‰å…¨é€€å‡º")


class GalbotG1Manipulator:
    def __init__(self, config: GalbotG1RobotConfig):
        self.config = config
        self.robot_type = self.config.type

        self.use_videos = self.config.use_videos

        self.microphones = self.config.microphones

        robot_ip = "127.0.0.1"
        self.robot_socket = RobotSocket(robot_ip)
        asyncio.run(Robot_main(self.robot_socket))


        self.leader_arms = {}
        self.leader_arms['main_leader'] = self.config.leader_arms["main"]

        self.follower_arms = {}
        self.follower_arms['main_follower'] = self.config.follower_arms["main"]

        self.cameras = make_cameras_from_configs(self.config.cameras)
        
        self.connect_excluded_cameras = ["image_pika_pose"]

        self.recv_image_thread = threading.Thread(target=recv_image_server, daemon=True)
        self.recv_image_thread.start()

        self.recv_joint_thread = threading.Thread(target=recv_joint_server, daemon=True)
        self.recv_joint_thread.start()

        
        self.is_connected = False
        self.logs = {}



    def get_motor_names(self, arms: dict[str, dict]) -> list:
        return [f"{arm}_{motor}" for arm, bus in arms.items() for motor in bus.motors]

    @property
    def camera_features(self) -> dict:
        cam_ft = {}
        for cam_key, cam in self.cameras.items():
            key = f"observation.images.{cam_key}"
            cam_ft[key] = {
                "shape": (cam.height, cam.width, cam.channels),
                "names": ["height", "width", "channels"],
                "info": None,
            }
        return cam_ft
    
    @property
    def microphone_features(self) -> dict:
        mic_ft = {}
        for mic_key, mic in self.microphones.items():
            key = f"observation.audio.{mic_key}"
            mic_ft[key] = {
                "shape": (1,),
                "names": ["channels"],
                "info": None,
            }
        return mic_ft
    
    @property
    def motor_features(self) -> dict:
        action_names = self.get_motor_names(self.leader_arms)
        state_names = self.get_motor_names(self.follower_arms)
        return {
            "action": {
                "dtype": "float32",
                "shape": (len(action_names),),
                "names": action_names,
            },
            "observation.state": {
                "dtype": "float32",
                "shape": (len(state_names),),
                "names": state_names,
            },
        }
    
    def connect(self):
        timeout = 50  # ç»Ÿä¸€çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        start_time = time.perf_counter()

        # å®šä¹‰æ‰€æœ‰éœ€è¦ç­‰å¾…çš„æ¡ä»¶åŠå…¶é”™è¯¯ä¿¡æ¯
        conditions = [
            (
                lambda: all(name in recv_images for name in self.cameras if name not in self.connect_excluded_cameras),
                lambda: [name for name in self.cameras if name not in recv_images],
                "ç­‰å¾…æ‘„åƒå¤´å›¾åƒè¶…æ—¶"
            ),
            (
                lambda: all(
                    any(name in key for key in recv_joint)
                    for name in self.leader_arms
                ),
                lambda: [name for name in self.leader_arms if not any(name in key for key in recv_joint)],
                "ç­‰å¾…ä¸»è‡‚å…³èŠ‚è§’åº¦è¶…æ—¶"
            ),
            (
                lambda: all(
                    any(name in key for key in recv_joint)
                    for name in self.follower_arms
                ),
                lambda: [name for name in self.follower_arms if not any(name in key for key in recv_joint)],
                "ç­‰å¾…ä»è‡‚å…³èŠ‚è§’åº¦è¶…æ—¶"
            ),
        ]

        # è·Ÿè¸ªæ¯ä¸ªæ¡ä»¶æ˜¯å¦å·²å®Œæˆ
        completed = [False] * len(conditions)

        while True:
            # æ£€æŸ¥æ¯ä¸ªæœªå®Œæˆçš„æ¡ä»¶
            for i in range(len(conditions)):
                if not completed[i]:
                    condition_func = conditions[i][0]
                    if condition_func():
                        completed[i] = True

            # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½å·²å®Œæˆï¼Œé€€å‡ºå¾ªç¯
            if all(completed):
                break

            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.perf_counter() - start_time > timeout:
                failed_messages = []
                for i in range(len(completed)):
                    if not completed[i]:
                        condition_func, get_missing, base_msg = conditions[i]
                        missing = get_missing()

                        # é‡æ–°æ£€æŸ¥æ¡ä»¶æ˜¯å¦æ»¡è¶³ï¼ˆå¯èƒ½åˆšå¥½åœ¨æœ€åä¸€æ¬¡æ£€æŸ¥åæ»¡è¶³ï¼‰
                        if condition_func():
                            completed[i] = True
                            continue

                        # å¦‚æœæ²¡æœ‰ missingï¼Œä¹Ÿè§†ä¸ºæ»¡è¶³
                        if not missing:
                            completed[i] = True
                            continue

                        # è®¡ç®—å·²æ¥æ”¶çš„é¡¹
                        if i == 0:
                            received = [name for name in self.cameras if name not in missing]
                        else:
                            received = [name for name in self.follower_arms if name not in missing]

                        # æ„é€ é”™è¯¯ä¿¡æ¯
                        msg = f"{base_msg}: æœªæ”¶åˆ° [{', '.join(missing)}]; å·²æ”¶åˆ° [{', '.join(received)}]"
                        failed_messages.append(msg)

                # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½å·²å®Œæˆï¼Œbreak
                if not failed_messages:
                    break

                # æŠ›å‡ºè¶…æ—¶å¼‚å¸¸
                raise TimeoutError(f"è¿æ¥è¶…æ—¶ï¼Œæœªæ»¡è¶³çš„æ¡ä»¶: {'; '.join(failed_messages)}")

            # å‡å°‘ CPU å ç”¨
            time.sleep(0.01)

        # ===== æ–°å¢æˆåŠŸæ‰“å°é€»è¾‘ =====
        success_messages = []
        # æ‘„åƒå¤´è¿æ¥çŠ¶æ€
        if conditions[0][0]():
            cam_received = [name for name in self.cameras 
                        if name in recv_images and name not in self.connect_excluded_cameras]
            success_messages.append(f"æ‘„åƒå¤´: {', '.join(cam_received)}")

        # ä¸»è‡‚æ•°æ®çŠ¶æ€
        arm_data_types = ["ä¸»è‡‚å…³èŠ‚è§’åº¦",]
        for i, data_type in enumerate(arm_data_types, 1):
            if conditions[i][0]():
                arm_received = [name for name in self.leader_arms 
                            if any(name in key for key in (recv_joint,)[i-1])]
                success_messages.append(f"{data_type}: {', '.join(arm_received)}")
        
        # ä»è‡‚æ•°æ®çŠ¶æ€
        arm_data_types = ["ä»è‡‚å…³èŠ‚è§’åº¦",]
        for i, data_type in enumerate(arm_data_types, 1):
            if conditions[i][0]():
                arm_received = [name for name in self.follower_arms 
                            if any(name in key for key in (recv_joint,)[i-1])]
                success_messages.append(f"{data_type}: {', '.join(arm_received)}")
        
        # æ‰“å°æˆåŠŸè¿æ¥ä¿¡æ¯
        print("\n[è¿æ¥æˆåŠŸ] æ‰€æœ‰è®¾å¤‡å·²å°±ç»ª:")
        for msg in success_messages:
            print(f"  - {msg}")
        print(f"  æ€»è€—æ—¶: {time.perf_counter() - start_time:.2f}ç§’\n")
        # ===========================

        self.is_connected = True
    
    @property
    def features(self):
        return {**self.motor_features, **self.camera_features}

    @property
    def has_camera(self):
        return len(self.cameras) > 0

    @property
    def num_cameras(self):
        return len(self.cameras)

    def teleop_step(
        self, record_data=False, 
    ) -> None | tuple[dict[str, torch.Tensor], dict[str, torch.Tensor]]:

        if not self.is_connected:
            raise RobotDeviceNotConnectedError(
                "Aloha is not connected. You need to run `robot.connect()`."
            )

        if not record_data:
            return

        follower_joint = {}
        for name in self.follower_arms:
            for match_name in recv_joint:
                if name in match_name:
                    now = time.perf_counter()

                    byte_array = np.zeros(6, dtype=np.float32)
                    pose_read = recv_joint[match_name]

                    byte_array[:6] = pose_read[:]
                    byte_array = np.round(byte_array, 3)
                    
                    follower_joint[name] = torch.from_numpy(byte_array)

                    self.logs[f"read_follower_{name}_joint_dt_s"] = time.perf_counter() - now
                    
        leader_joint = {}
        for name in self.leader_arms:
            for match_name in recv_joint:
                if name in match_name:
                    now = time.perf_counter()

                    byte_array = np.zeros(6, dtype=np.float32)
                    pose_read = recv_joint[match_name]

                    byte_array[:6] = pose_read[:]
                    byte_array = np.round(byte_array, 3)
                    
                    leader_joint[name] = torch.from_numpy(byte_array)

                    self.logs[f"read_leader_{name}_joint_dt_s"] = time.perf_counter() - now

        #è®°å½•å½“å‰å…³èŠ‚è§’åº¦
        state = []
        for name in self.follower_arms:
            if name in follower_joint:
                state.append(follower_joint[name])
        state = torch.cat(state)

        #å°†å…³èŠ‚ç›®æ ‡ä½ç½®æ·»åŠ åˆ° action åˆ—è¡¨ä¸­
        action = []
        for name in self.leader_arms:
            if name in leader_joint:
                action.append(leader_joint[name])
        action = torch.cat(action)

        # Capture images from cameras
        images = {}
        for name in self.cameras:
            now = time.perf_counter()
            images[name] = recv_images[name]
            images[name] = torch.from_numpy(images[name])
            self.logs[f"read_camera_{name}_dt_s"] = time.perf_counter() - now

        # Populate output dictionnaries and format to pytorch
        obs_dict, action_dict = {}, {}
        obs_dict["observation.state"] = state
        action_dict["action"] = action
        for name in self.cameras:
            obs_dict[f"observation.images.{name}"] = images[name]

        # print("end teleoperate record")
        return obs_dict, action_dict


    # def capture_observation(self):
    #     if not self.is_connected:
    #         raise RobotDeviceNotConnectedError(
    #             "KochRobot is not connected. You need to run `robot.connect()`."
    #         )

    #     #è°ƒç”¨ä»è‡‚apiè·å–å½“å‰å…³èŠ‚è§’åº¦ 
    #     for name in self.leader_arms:
    #         now = time.perf_counter()
    #         self.pDll.Get_Joint_Degree(self.nSocket,self.joint_obs_read)  
    #         #å¤¹çˆªé€šä¿¡è·å–å½“å‰å¤¹çˆªå¼€åˆåº¦
    #         #   giper_read=ctypes.c_int()
    #         #   self.pDll.Get_Read_Holding_Registers(self.nSocket,1,40005,1,ctypes.byref(giper_read))
    #         #   #å…«ä½æ•°ç»„å­˜å‚¨å…³èŠ‚å’Œå¤¹çˆªæ•°æ®
    #         self.joint_obs_present[:7]=self.joint_obs_read[:]
    #         #   self.joint_obs_present[7]=giper_read.value
    #         if self.gipflag_send==1:
    #             self.joint_obs_present[7]=100
    #         elif self.gipflag_send==0:
    #             self.joint_obs_present[7]=10
    #         # self.joint_obs_present = np.zeros(8)  # åˆ›å»ºä¸€ä¸ªåŒ…å«å…«ä¸ª0çš„ NumPy æ•°ç»„
    #         self.logs[f"read_follower_{name}_pos_dt_s"] = time.perf_counter() - now

    #     # Create state by concatenating follower current position
    #     #ä¸Šä¼ å½“å‰æœºæ¢°è‡‚çŠ¶æ€
    #     state = []
    #     self.joint_obs_present = np.round(self.joint_obs_present, 2)
    #     joint_array_np = np.array( self.joint_obs_present)
    #     state = np.array([joint_array_np], dtype=np.float32)
    #     state = np.concatenate(state, dtype=np.float32)

    #     # Capture images from cameras
    #     images = {}
    #     for name in self.cameras:
    #         now = time.perf_counter()
    #         images[name] = self.cameras[name].async_read()
    #         self.logs[f"read_camera_{name}_dt_s"] = self.cameras[name].logs["delta_timestamp_s"]
    #         self.logs[f"async_read_camera_{name}_dt_s"] = time.perf_counter() - now

    #     # Populate output dictionnaries and format to pytorch
    #     obs_dict = {}
    #     obs_dict["observation.state"] = torch.from_numpy(state)
    #     for name in self.cameras:
    #         # Convert to pytorch format: channel first and float32 in [0,1]
    #         img = torch.from_numpy(images[name])
    #         img = img.type(torch.float32) / 255
    #         img = img.permute(2, 0, 1).contiguous()
    #         obs_dict[f"observation.images.{name}"] = img
    #     return obs_dict    def capture_observation(self):

    # def capture_observation(self):
    #     if not self.is_connected:
    #         raise RobotDeviceNotConnectedError(
    #             "KochRobot is not connected. You need to run `robot.connect()`."
    #         )

    #     follower_pos = {}
    #     for name in self.follower_arms:
    #         now = time.perf_counter()
    #         eight_byte_array = np.zeros(8, dtype=np.float32)
    #         joint_obs_read = self.follower_arms[name].async_read_joint_degree()

    #         #å¤¹çˆªé€šä¿¡è·å–å½“å‰å¤¹çˆªå¼€åˆåº¦
    #         # giper_read=ctypes.c_int()
    #         # self.pDll.Get_Read_Holding_Registers(self.nSocket,1,40000,1,ctypes.byref(giper_read))
    #         #   #å…«ä½æ•°ç»„å­˜å‚¨å…³èŠ‚å’Œå¤¹çˆªæ•°æ®
    #         eight_byte_array[:7] = joint_obs_read[:]
    #         # self.joint_obs_present[7]=giper_read.value
    #         eight_byte_array[7] = self.follower_arms[name].old_grasp
    #         # self.joint_obs_present = np.zeros(8)  # åˆ›å»ºä¸€ä¸ªåŒ…å«å…«ä¸ª0çš„ NumPy æ•°ç»„
    #         eight_byte_array = np.round(eight_byte_array, 2)
    #         follower_pos[name] = torch.from_numpy(eight_byte_array)
    #         self.logs[f"read_follower_{name}_pos_dt_s"] = time.perf_counter() - now

    #     # Create state by concatenating follower current position
    #     #ä¸Šä¼ å½“å‰æœºæ¢°è‡‚çŠ¶æ€
    #     state = []
    #     for name in self.follower_arms:
    #         if name in follower_pos:
    #             state.append(follower_pos[name])    
    #     state = torch.cat(state)

    #     # Capture images from cameras
    #     images = {}
    #     for name in self.cameras:
    #         now = time.perf_counter()
    #         images[name] = self.cameras[name].async_read()
    #         images[name] = torch.from_numpy(images[name])
    #         self.logs[f"read_camera_{name}_dt_s"] = self.cameras[name].logs["delta_timestamp_s"]
    #         self.logs[f"async_read_camera_{name}_dt_s"] = time.perf_counter() - now

    #     # Populate output dictionnaries and format to pytorch
    #     obs_dict = {}
    #     obs_dict["observation.state"] = state
    #     for name in self.cameras:
    #         obs_dict[f"observation.images.{name}"] = images[name]
    #     return obs_dict

    def send_action(self, action: dict[str, Any]):
        """The provided action is expected to be a vector."""
        if not self.is_connected:
            raise RobotDeviceNotConnectedError(
                "KochRobot is not connected. You need to run `robot.connect()`."
            )

        for name in self.leader_arms:
            goal_joint = [ val for key, val in action.items() if name in key and "joint" in key]
            # goal_gripper = [ val for key, val in action.items() if name in key and "gripper" in key]

            # goal_joint = action[(arm_index*arm_action_dim+from_idx):(arm_index*arm_action_dim+to_idx)]
            # goal_gripper = action[arm_index*arm_action_dim + 12]
            # arm_index += 1
            goal_joint_numpy = np.array([t.item() for t in goal_joint], dtype=np.float32)
            # goal_gripper_numpy = np.array([t.item() for t in goal_gripper], dtype=np.float32)
            # position = np.concatenate([goal_joint_numpy, goal_gripper_numpy], axis=0)

            so101_zmq_send(f"action_joint_{name}", goal_joint_numpy, wait_time_s=0.01)


    def disconnect(self):
        if not self.is_connected:
            raise RobotDeviceNotConnectedError(
                "Aloha is not connected. You need to run `robot.connect()` before disconnecting."
            )

        self.is_connected = False
        global running_recv_image_server
        global running_recv_joint_server
        running_recv_image_server = False
        running_recv_joint_server = False

        self.robot_socket.shutdown()

        self.recv_image_thread.join()
        self.recv_joint_thread.join()
        

    def __del__(self):
        if getattr(self, "is_connected", False):
            self.disconnect()
